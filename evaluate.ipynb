{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                     model                                           baseline  \\\n",
      "0   gpt-4o-mini-2024-07-18  o CEP do endereço QNM 07 CONJUNTO H LOTE 17 S/...   \n",
      "1   gpt-4o-mini-2024-07-18  o CEP do endereço QI 13 LOTE 01 A 14 ALA 01 BO...   \n",
      "2   gpt-4o-mini-2024-07-18  o CEP do endereço SHC/ SW CLSW 103 BL A S/N LO...   \n",
      "3   gpt-4o-mini-2024-07-18  o CEP do endereço 06 CONJUNTO 05/06 LOTE 3-A S...   \n",
      "4   gpt-4o-mini-2024-07-18  o CEP do endereço SHCS CR QD 516, BLOCO B 69 1...   \n",
      "..                     ...                                                ...   \n",
      "95  gpt-4o-mini-2024-07-18  o CEP do endereço QD 104 CJ 09 LT 02 RECANTO D...   \n",
      "96  gpt-4o-mini-2024-07-18  o CEP do endereço QNB 13 LOTE 37 CASA 01 TAGUA...   \n",
      "97  gpt-4o-mini-2024-07-18  o CEP do endereço CRS 502 BL C LJ 37 PARTE 677...   \n",
      "98  gpt-4o-mini-2024-07-18  o CEP do endereço QUADRA 1 COMERCIO LOCAL S/N ...   \n",
      "99  gpt-4o-mini-2024-07-18  o CEP do endereço QS 9 RUA 122 LOTE 08 LOJA 03...   \n",
      "\n",
      "                                              results  \n",
      "0   Não há dados suficientes para responder com se...  \n",
      "1   Não há dados suficientes para responder com se...  \n",
      "2   Não há dados suficientes para responder com se...  \n",
      "3   Não há dados suficientes para responder com se...  \n",
      "4   Não há dados suficientes para responder com se...  \n",
      "..                                                ...  \n",
      "95  Não há dados suficientes para responder com se...  \n",
      "96  Não há dados suficientes para responder com se...  \n",
      "97  O CEP do endereço CRS 502 Bloco B não está esp...  \n",
      "98  Não há dados suficientes para responder com se...  \n",
      "99  Não há dados suficientes para responder com se...  \n",
      "\n",
      "[100 rows x 3 columns],                          model  \\\n",
      "0   TeenyTinyLlama-160m-CEP-ft   \n",
      "1   TeenyTinyLlama-160m-CEP-ft   \n",
      "2   TeenyTinyLlama-160m-CEP-ft   \n",
      "3   TeenyTinyLlama-160m-CEP-ft   \n",
      "4   TeenyTinyLlama-160m-CEP-ft   \n",
      "..                         ...   \n",
      "95  TeenyTinyLlama-160m-CEP-ft   \n",
      "96  TeenyTinyLlama-160m-CEP-ft   \n",
      "97  TeenyTinyLlama-160m-CEP-ft   \n",
      "98  TeenyTinyLlama-160m-CEP-ft   \n",
      "99  TeenyTinyLlama-160m-CEP-ft   \n",
      "\n",
      "                                             baseline  \\\n",
      "0   o CEP do endereço QNM 07 CONJUNTO H LOTE 17 S/...   \n",
      "1   o CEP do endereço QI 13 LOTE 01 A 14 ALA 01 BO...   \n",
      "2   o CEP do endereço SHC/ SW CLSW 103 BL A S/N LO...   \n",
      "3   o CEP do endereço 06 CONJUNTO 05/06 LOTE 3-A S...   \n",
      "4   o CEP do endereço SHCS CR QD 516, BLOCO B 69 1...   \n",
      "..                                                ...   \n",
      "95  o CEP do endereço QD 104 CJ 09 LT 02 RECANTO D...   \n",
      "96  o CEP do endereço QNB 13 LOTE 37 CASA 01 TAGUA...   \n",
      "97  o CEP do endereço CRS 502 BL C LJ 37 PARTE 677...   \n",
      "98  o CEP do endereço QUADRA 1 COMERCIO LOCAL S/N ...   \n",
      "99  o CEP do endereço QS 9 RUA 122 LOTE 08 LOJA 03...   \n",
      "\n",
      "                                              results  \n",
      "0    \\n\\nSe a informação for insuficiente, forneça...  \n",
      "1    \\n\\nVocê está correto no seu ponto de vista:\\...  \n",
      "2    \\n\\nSe a informação for fornecida como parte ...  \n",
      "3    \\n\\nComo alternativa, você pode entrar em con...  \n",
      "4    \\n\\nSe a informação for fornecida como parte ...  \n",
      "..                                                ...  \n",
      "95   \\n\\nSe a pergunta for sobre o CEP do endereço...  \n",
      "96   \\n\\nVocê está qualificado a responder as segu...  \n",
      "97   \\n\\nSe o contexto não contiver informações su...  \n",
      "98   \\n\\nVocê está procurando informações sobre a ...  \n",
      "99   \\n\\nVocê está a tratar da seguinte pergunta:\\...  \n",
      "\n",
      "[100 rows x 3 columns],              model                                           baseline  \\\n",
      "0   TeenyTinyLlama  o CEP do endereço QNM 07 CONJUNTO H LOTE 17 S/...   \n",
      "1   TeenyTinyLlama  o CEP do endereço QI 13 LOTE 01 A 14 ALA 01 BO...   \n",
      "2   TeenyTinyLlama  o CEP do endereço SHC/ SW CLSW 103 BL A S/N LO...   \n",
      "3   TeenyTinyLlama  o CEP do endereço 06 CONJUNTO 05/06 LOTE 3-A S...   \n",
      "4   TeenyTinyLlama  o CEP do endereço SHCS CR QD 516, BLOCO B 69 1...   \n",
      "..             ...                                                ...   \n",
      "95  TeenyTinyLlama  o CEP do endereço QD 104 CJ 09 LT 02 RECANTO D...   \n",
      "96  TeenyTinyLlama  o CEP do endereço QNB 13 LOTE 37 CASA 01 TAGUA...   \n",
      "97  TeenyTinyLlama  o CEP do endereço CRS 502 BL C LJ 37 PARTE 677...   \n",
      "98  TeenyTinyLlama  o CEP do endereço QUADRA 1 COMERCIO LOCAL S/N ...   \n",
      "99  TeenyTinyLlama  o CEP do endereço QS 9 RUA 122 LOTE 08 LOJA 03...   \n",
      "\n",
      "                                              results  \n",
      "0    \\n\\nSe a informação estiver incorreta, indiqu...  \n",
      "1    \\n\\nSe a informação estiver incorreta, verifi...  \n",
      "2    \\n\\nSe a resposta for sim, informe-nos sobre ...  \n",
      "3    \\n\\nResumo das respostas:\\n\\nPedido de inform...  \n",
      "4    \\n\\nSe a resposta for sim, informe-nos sobre ...  \n",
      "..                                                ...  \n",
      "95   \\n\\nSe a resposta for sim, indique que não ho...  \n",
      "96   \\n\\nSe a resposta for sim, informe-nos sobre ...  \n",
      "97   \\n\\nSe o contexto não contiver informações su...  \n",
      "98   \\n\\nSe o contexto não contiver informações su...  \n",
      "99   \\n\\nSe a informação estiver incorreta, verifi...  \n",
      "\n",
      "[100 rows x 3 columns]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the path to the results directory\n",
    "results_dir = \"results\"\n",
    "\n",
    "# Function to extract model name from filename\n",
    "def extract_model_name(filename):\n",
    "    match = re.search(r\"experimental_design_results_(.*)\\.csv\", filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return \"Unknown Model\"\n",
    "\n",
    "# Function to read CSV files from a directory, add 'model' column, and select specific columns\n",
    "def read_and_label_csvs(directory):\n",
    "    dfs = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(filepath, encoding='utf-8')\n",
    "            \n",
    "                model_name = extract_model_name(filename)\n",
    "                df['model'] = model_name  # Add model name as a column\n",
    "                \n",
    "                # Select specific columns\n",
    "                df = df[['model', 'baseline', 'results']]\n",
    "                \n",
    "                dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "    return dfs\n",
    "\n",
    "# Read and label CSV files from the results directory\n",
    "df = read_and_label_csvs(results_dir)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Specify the path to your .env file\n",
    "dotenv_path = \"/mnt/4d4f90e5-f220-481e-8701-f0a546491c35/arquivos/projetos/.env\"\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "# Access and store the environment variable\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = 'gpt-4o-mini-2024-07-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:03<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "  \"quality\": 2,\n",
      "  \"agreement\": 3,\n",
      "  \"accuracy\": 4,\n",
      "  \"justification\": \"A resposta do modelo é repetitiva e não fornece informações específicas sobre os CEPs solicitados, o que compromete a clareza e a estrutura da resposta. Embora algumas respostas mencionem que não há dados suficientes, isso não é verdade, pois a baseline contém informações claras sobre os CEPs. A concordância é baixa, pois a resposta não aborda diretamente a questão proposta. A precisão é um pouco melhor em uma das respostas, mas a maioria não apresenta informações úteis, resultando em uma nota geral baixa.\"\n",
      "}\n",
      "```\n",
      "{'quality': 2, 'agreement': 3, 'accuracy': 4, 'justification': 'A resposta do modelo é repetitiva e não fornece informações específicas sobre os CEPs solicitados, o que compromete a clareza e a estrutura da resposta. Embora algumas respostas mencionem que não há dados suficientes, isso não é verdade, pois a baseline contém informações claras sobre os CEPs. A concordância é baixa, pois a resposta não aborda diretamente a questão proposta. A precisão é um pouco melhor em uma das respostas, mas a maioria não apresenta informações úteis, resultando em uma nota geral baixa.'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Iterate over each row and make API call\n",
    "for index, row in tqdm(enumerate(df), total=len(df)):\n",
    "    if index % 100 == 0 and index != 0:\n",
    "        print(\"min. pause...\")\n",
    "        time.sleep(60)\n",
    "    baseline = row['baseline']\n",
    "    result = row['results']\n",
    "    temperature = 0.0\n",
    "    comparison_promt = f\"\"\"Avalie as respostas abaixo de 0 a 10, considerando os seguintes critérios:\n",
    "\n",
    "        *Qualidade da Resposta*: A resposta é clara, concisa e bem estruturada? Ela aborda diretamente a questão ou tarefa proposta?\n",
    "        *Concordância*: A resposta faz sentido no contexto da pergunta ou instrução? Ela segue uma linha de raciocínio coerente?\n",
    "        *Precisão/Acurácia*: A resposta apresenta informações corretas e verificáveis comparadas com o baseline? Ela evita informações falsas ou enganosas?\n",
    "\n",
    "        Resposta Base (Baseline): {baseline}\n",
    "        Resposta do Modelo: {result}\n",
    "\n",
    "        Atribua uma nota de 0 a 10 para a comparação entre as respostas (Baseline e Modelo), justificando brevemente sua avaliação. Retorne a avaliação no formato JSON, com as chaves \"quality\", \"agreement\", \"accuracy\" e \"justification\".\n",
    "        \"\"\"\n",
    "        \n",
    "    response = openai.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": comparison_promt}],\n",
    "        temperature=temperature\n",
    "    )\n",
    "    generated_text = response.choices[0].message.content\n",
    "    \n",
    "    # Load the JSON string\n",
    "    metadata_str = generated_text.strip()\n",
    "    if metadata_str.startswith(\"```json\") and metadata_str.endswith(\"```\"):\n",
    "        metadata_str = metadata_str.strip(\"```\").strip()\n",
    "    if metadata_str.startswith(\"json\"):\n",
    "        metadata_str = metadata_str[4:].lstrip()\n",
    "    data = pd.DataFrame([json.loads(metadata_str)])\n",
    "    print(data)\n",
    "    \n",
    "    break\n",
    "    \n",
    "# Save the updated DataFrame\n",
    "#output_filename = f\"results/experimental_design_results_{model_name}.csv\"\n",
    "#df.to_csv(output_filename, index=False)\n",
    "\n",
    "#print(f\"Completed. Results saved in {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   quality  agreement  accuracy  \\\n",
      "0        2          3         4   \n",
      "\n",
      "                                       justification  \n",
      "0  A resposta do modelo é repetitiva e não fornec...  \n"
     ]
    }
   ],
   "source": [
    "# Load the JSON string\n",
    "metadata_str = generated_text.strip()\n",
    "if metadata_str.startswith(\"```json\") and metadata_str.endswith(\"```\"):\n",
    "    metadata_str = metadata_str.strip(\"```\").strip()\n",
    "if metadata_str.startswith(\"json\"):\n",
    "    metadata_str = metadata_str[4:].lstrip()\n",
    "data = pd.DataFrame([json.loads(metadata_str)])\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import json\n",
    "\n",
    "# Iterate over each row and make API call\n",
    "output_filename = f\"model scoring.csv\"\n",
    "final_df['evaluation'] = None\n",
    "\n",
    "# Initialize progress bar\n",
    "progress_bar = IntProgress(min=0, max=len(final_df), desc=f\"Processing {model}\")\n",
    "display(progress_bar)\n",
    "\n",
    "for index, row in final_df.iterrows():\n",
    "    if index % 100 == 0 and index != 0:\n",
    "        print(\"min. pause...\")\n",
    "        time.sleep(60)\n",
    "    try:\n",
    "        tmp_comparison_prompt = row['comparison_prompt']\n",
    "\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": tmp_comparison_prompt}],\n",
    "            temperature=float(row['temperature']),\n",
    "            top_p=float(row['top_p'])\n",
    "        )\n",
    "\n",
    "        # Extract and store the generated text\n",
    "        metadata_str = response.choices[0].message.content.strip()\n",
    "        if metadata_str.startswith(\"```json\") and metadata_str.endswith(\"```\"):\n",
    "            metadata_str = metadata_str.strip(\"```\").strip()\n",
    "        if metadata_str.startswith(\"json\"):\n",
    "            metadata_str = metadata_str[4:].lstrip()\n",
    "        metadata = json.loads(metadata_str)\n",
    "\n",
    "        filters = {}\n",
    "        if isinstance(metadata, dict):\n",
    "            filters = {k: v for k, v in metadata.items() if v is not None}\n",
    "\n",
    "        final_df.loc[index, 'evaluation'] = filters\n",
    "\n",
    "    except openai.OpenAIError as e:\n",
    "        print(f\"Error processing row {index} for model {model}: {e}\")\n",
    "        final_df.loc[index, 'evaluation'] = f\"Error: {e}\"  # Store the error message\n",
    "    except Exception as e:\n",
    "        print(f\"Unexpected error processing row {index} for model {model}: {e}\")\n",
    "        final_df.loc[index, 'evaluation'] = f\"Error: {e}\"\n",
    "\n",
    "    # Update progress bar\n",
    "    progress_bar.value += 1\n",
    "\n",
    "# Save the updated DataFrame (optional)\n",
    "final_df.to_csv(output_filename, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[                     model                                           baseline  \\\n",
      "0   gpt-4o-mini-2024-07-18  o CEP do endereço QNM 07 CONJUNTO H LOTE 17 S/...   \n",
      "1   gpt-4o-mini-2024-07-18  o CEP do endereço QI 13 LOTE 01 A 14 ALA 01 BO...   \n",
      "2   gpt-4o-mini-2024-07-18  o CEP do endereço SHC/ SW CLSW 103 BL A S/N LO...   \n",
      "3   gpt-4o-mini-2024-07-18  o CEP do endereço 06 CONJUNTO 05/06 LOTE 3-A S...   \n",
      "4   gpt-4o-mini-2024-07-18  o CEP do endereço SHCS CR QD 516, BLOCO B 69 1...   \n",
      "..                     ...                                                ...   \n",
      "95  gpt-4o-mini-2024-07-18  o CEP do endereço QD 104 CJ 09 LT 02 RECANTO D...   \n",
      "96  gpt-4o-mini-2024-07-18  o CEP do endereço QNB 13 LOTE 37 CASA 01 TAGUA...   \n",
      "97  gpt-4o-mini-2024-07-18  o CEP do endereço CRS 502 BL C LJ 37 PARTE 677...   \n",
      "98  gpt-4o-mini-2024-07-18  o CEP do endereço QUADRA 1 COMERCIO LOCAL S/N ...   \n",
      "99  gpt-4o-mini-2024-07-18  o CEP do endereço QS 9 RUA 122 LOTE 08 LOJA 03...   \n",
      "\n",
      "                                              results  \n",
      "0   Não há dados suficientes para responder com se...  \n",
      "1   Não há dados suficientes para responder com se...  \n",
      "2   Não há dados suficientes para responder com se...  \n",
      "3   Não há dados suficientes para responder com se...  \n",
      "4   Não há dados suficientes para responder com se...  \n",
      "..                                                ...  \n",
      "95  Não há dados suficientes para responder com se...  \n",
      "96  Não há dados suficientes para responder com se...  \n",
      "97  O CEP do endereço CRS 502 Bloco B não está esp...  \n",
      "98  Não há dados suficientes para responder com se...  \n",
      "99  Não há dados suficientes para responder com se...  \n",
      "\n",
      "[100 rows x 3 columns],                          model  \\\n",
      "0   TeenyTinyLlama-160m-CEP-ft   \n",
      "1   TeenyTinyLlama-160m-CEP-ft   \n",
      "2   TeenyTinyLlama-160m-CEP-ft   \n",
      "3   TeenyTinyLlama-160m-CEP-ft   \n",
      "4   TeenyTinyLlama-160m-CEP-ft   \n",
      "..                         ...   \n",
      "95  TeenyTinyLlama-160m-CEP-ft   \n",
      "96  TeenyTinyLlama-160m-CEP-ft   \n",
      "97  TeenyTinyLlama-160m-CEP-ft   \n",
      "98  TeenyTinyLlama-160m-CEP-ft   \n",
      "99  TeenyTinyLlama-160m-CEP-ft   \n",
      "\n",
      "                                             baseline  \\\n",
      "0   o CEP do endereço QNM 07 CONJUNTO H LOTE 17 S/...   \n",
      "1   o CEP do endereço QI 13 LOTE 01 A 14 ALA 01 BO...   \n",
      "2   o CEP do endereço SHC/ SW CLSW 103 BL A S/N LO...   \n",
      "3   o CEP do endereço 06 CONJUNTO 05/06 LOTE 3-A S...   \n",
      "4   o CEP do endereço SHCS CR QD 516, BLOCO B 69 1...   \n",
      "..                                                ...   \n",
      "95  o CEP do endereço QD 104 CJ 09 LT 02 RECANTO D...   \n",
      "96  o CEP do endereço QNB 13 LOTE 37 CASA 01 TAGUA...   \n",
      "97  o CEP do endereço CRS 502 BL C LJ 37 PARTE 677...   \n",
      "98  o CEP do endereço QUADRA 1 COMERCIO LOCAL S/N ...   \n",
      "99  o CEP do endereço QS 9 RUA 122 LOTE 08 LOJA 03...   \n",
      "\n",
      "                                              results  \n",
      "0    \\n\\nSe a informação for insuficiente, forneça...  \n",
      "1    \\n\\nVocê está correto no seu ponto de vista:\\...  \n",
      "2    \\n\\nSe a informação for fornecida como parte ...  \n",
      "3    \\n\\nComo alternativa, você pode entrar em con...  \n",
      "4    \\n\\nSe a informação for fornecida como parte ...  \n",
      "..                                                ...  \n",
      "95   \\n\\nSe a pergunta for sobre o CEP do endereço...  \n",
      "96   \\n\\nVocê está qualificado a responder as segu...  \n",
      "97   \\n\\nSe o contexto não contiver informações su...  \n",
      "98   \\n\\nVocê está procurando informações sobre a ...  \n",
      "99   \\n\\nVocê está a tratar da seguinte pergunta:\\...  \n",
      "\n",
      "[100 rows x 3 columns],              model                                           baseline  \\\n",
      "0   TeenyTinyLlama  o CEP do endereço QNM 07 CONJUNTO H LOTE 17 S/...   \n",
      "1   TeenyTinyLlama  o CEP do endereço QI 13 LOTE 01 A 14 ALA 01 BO...   \n",
      "2   TeenyTinyLlama  o CEP do endereço SHC/ SW CLSW 103 BL A S/N LO...   \n",
      "3   TeenyTinyLlama  o CEP do endereço 06 CONJUNTO 05/06 LOTE 3-A S...   \n",
      "4   TeenyTinyLlama  o CEP do endereço SHCS CR QD 516, BLOCO B 69 1...   \n",
      "..             ...                                                ...   \n",
      "95  TeenyTinyLlama  o CEP do endereço QD 104 CJ 09 LT 02 RECANTO D...   \n",
      "96  TeenyTinyLlama  o CEP do endereço QNB 13 LOTE 37 CASA 01 TAGUA...   \n",
      "97  TeenyTinyLlama  o CEP do endereço CRS 502 BL C LJ 37 PARTE 677...   \n",
      "98  TeenyTinyLlama  o CEP do endereço QUADRA 1 COMERCIO LOCAL S/N ...   \n",
      "99  TeenyTinyLlama  o CEP do endereço QS 9 RUA 122 LOTE 08 LOJA 03...   \n",
      "\n",
      "                                              results  \n",
      "0    \\n\\nSe a informação estiver incorreta, indiqu...  \n",
      "1    \\n\\nSe a informação estiver incorreta, verifi...  \n",
      "2    \\n\\nSe a resposta for sim, informe-nos sobre ...  \n",
      "3    \\n\\nResumo das respostas:\\n\\nPedido de inform...  \n",
      "4    \\n\\nSe a resposta for sim, informe-nos sobre ...  \n",
      "..                                                ...  \n",
      "95   \\n\\nSe a resposta for sim, indique que não ho...  \n",
      "96   \\n\\nSe a resposta for sim, informe-nos sobre ...  \n",
      "97   \\n\\nSe o contexto não contiver informações su...  \n",
      "98   \\n\\nSe o contexto não contiver informações su...  \n",
      "99   \\n\\nSe a informação estiver incorreta, verifi...  \n",
      "\n",
      "[100 rows x 3 columns]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Define the path to the results directory\n",
    "results_dir = \"results\"\n",
    "\n",
    "# Function to extract model name from filename\n",
    "def extract_model_name(filename):\n",
    "    match = re.search(r\"experimental_design_results_(.*)\\.csv\", filename)\n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return \"Unknown Model\"\n",
    "\n",
    "# Function to read CSV files from a directory, add 'model' column, and select specific columns\n",
    "def read_and_label_csvs(directory):\n",
    "    dfs = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.endswith(\".csv\"):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            try:\n",
    "                df = pd.read_csv(filepath, encoding='utf-8')\n",
    "            \n",
    "                model_name = extract_model_name(filename)\n",
    "                df['model'] = model_name  # Add model name as a column\n",
    "                \n",
    "                # Select specific columns\n",
    "                df = df[['model', 'baseline', 'results']]\n",
    "                \n",
    "                dfs.append(df)\n",
    "            except Exception as e:\n",
    "                print(f\"Error reading {filename}: {e}\")\n",
    "    return dfs\n",
    "\n",
    "# Read and label CSV files from the results directory\n",
    "df = read_and_label_csvs(results_dir)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import openai\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "# Specify the path to your .env file\n",
    "dotenv_path = \"/mnt/4d4f90e5-f220-481e-8701-f0a546491c35/arquivos/projetos/.env\"\n",
    "\n",
    "# Load the .env file\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "# Access and store the environment variable\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "model = 'gpt-4o-mini-2024-07-18'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "723fca6065844380807561aeca6a2ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "IntProgress(value=0, bar_style='info', max=300)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min. pause...\n",
      "min. pause...\n",
      "Completed. Results saved in final_evaluation.csv\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from ipywidgets import IntProgress\n",
    "from IPython.display import display\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize progress bar\n",
    "progress_bar = IntProgress(min=0, max=len(df), desc='Avaliando', bar_style='info')\n",
    "display(progress_bar)\n",
    "\n",
    "# Ensure df is a pandas DataFrame\n",
    "if isinstance(df, list):\n",
    "    print(\"Converting list of DataFrames to a single DataFrame.\")\n",
    "    df = pd.concat(df, ignore_index=True)\n",
    "\n",
    "# Iterate over each row and make API call\n",
    "for index, row in df.iterrows():\n",
    "    if index % 100 == 0 and index != 0:\n",
    "        print(\"min. pause...\")\n",
    "        time.sleep(60)\n",
    "    baseline = row['baseline']\n",
    "    result = row['results']\n",
    "    temperature = 0.0\n",
    "    comparison_promt = f\"\"\"Avalie as respostas abaixo de 0 a 10, considerando os seguintes critérios:\n",
    "\n",
    "        *Qualidade da Resposta*: A resposta é clara, concisa e bem estruturada? Ela aborda diretamente a questão ou tarefa proposta?\n",
    "        *Concordância*: A resposta faz sentido no contexto da pergunta ou instrução? Ela segue uma linha de raciocínio coerente?\n",
    "        *Precisão/Acurácia*: A resposta apresenta informações corretas e verificáveis comparadas com o baseline? Ela evita informações falsas ou enganosas?\n",
    "\n",
    "        Resposta Base (Baseline): {baseline}\n",
    "        Resposta do Modelo: {result}\n",
    "\n",
    "        Atribua uma nota de 0 a 10 para a comparação entre as respostas (Baseline e Modelo), justificando brevemente sua avaliação. Retorne a avaliação no formato JSON, com as chaves \"quality\", \"agreement\", \"accuracy\" e \"justification\".\n",
    "        \"\"\"\n",
    "        \n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[{\"role\": \"user\", \"content\": comparison_promt}],\n",
    "            temperature=temperature\n",
    "        )\n",
    "        generated_text = response.choices[0].message.content\n",
    "        \n",
    "        # Load the JSON string\n",
    "        metadata_str = generated_text.strip()\n",
    "        if metadata_str.startswith(\"```json\") and metadata_str.endswith(\"```\"):\n",
    "            metadata_str = metadata_str.strip(\"```\").strip()\n",
    "        if metadata_str.startswith(\"json\"):\n",
    "            metadata_str = metadata_str[4:].lstrip()\n",
    "        try:\n",
    "            data = json.loads(metadata_str)\n",
    "            # Update DataFrame with the extracted values\n",
    "            df.loc[index, 'quality'] = data.get('quality')\n",
    "            df.loc[index, 'agreement'] = data.get('agreement')\n",
    "            df.loc[index, 'accuracy'] = data.get('accuracy')\n",
    "            df.loc[index, 'justification'] = data.get('justification')\n",
    "            \n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Erro ao decodificar JSON: {e}\")\n",
    "            print(f\"String JSON com problema: {metadata_str}\")\n",
    "            # Optionally, store the error message in the DataFrame\n",
    "            df.loc[index, 'quality'] = None\n",
    "            df.loc[index, 'agreement'] = None\n",
    "            df.loc[index, 'accuracy'] = None\n",
    "            df.loc[index, 'justification'] = f\"Erro de JSON: {e}\"\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao processar a linha {index}: {e}\")\n",
    "        df.loc[index, 'quality'] = None\n",
    "        df.loc[index, 'agreement'] = None\n",
    "        df.loc[index, 'accuracy'] = None\n",
    "        df.loc[index, 'justification'] = f\"Erro: {e}\"\n",
    "    \n",
    "    progress_bar.value += 1\n",
    "        \n",
    "# Save the updated DataFrame\n",
    "output_filename = f\"final_evaluation.csv\"\n",
    "df.to_csv(output_filename, index=False)\n",
    "print(f\"Completed. Results saved in {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      model  quality  agreement  accuracy  evaluation\n",
      "0    gpt-4o-mini-2024-07-18      2.0        3.0       1.0    2.000000\n",
      "1    gpt-4o-mini-2024-07-18      3.0        2.0       2.0    2.333333\n",
      "2    gpt-4o-mini-2024-07-18      2.0        2.0       1.0    1.666667\n",
      "3    gpt-4o-mini-2024-07-18      2.0        2.0       1.0    1.666667\n",
      "4    gpt-4o-mini-2024-07-18      2.0        2.0       1.0    1.666667\n",
      "..                      ...      ...        ...       ...         ...\n",
      "295          TeenyTinyLlama      1.0        1.0       1.0    1.000000\n",
      "296          TeenyTinyLlama      3.0        2.0       2.0    2.333333\n",
      "297          TeenyTinyLlama      2.0        1.0       1.0    1.333333\n",
      "298          TeenyTinyLlama      3.0        2.0       1.0    2.000000\n",
      "299          TeenyTinyLlama      3.0        2.0       2.0    2.333333\n",
      "\n",
      "[300 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"final_evaluation.csv\")\n",
    "\n",
    "df_final = df[['model', 'quality', 'agreement', 'accuracy']].copy()\n",
    "\n",
    "# Converter colunas para numérico, tratando erros com NaN\n",
    "df_final.loc[:, 'quality'] = pd.to_numeric(df_final['quality'], errors='coerce')\n",
    "df_final.loc[:, 'agreement'] = pd.to_numeric(df_final['agreement'], errors='coerce')\n",
    "df_final.loc[:, 'accuracy'] = pd.to_numeric(df_final['accuracy'], errors='coerce')\n",
    "\n",
    "# Criar a coluna 'evaluation' com a média das outras três\n",
    "df_final['evaluation'] = df_final[['quality', 'agreement', 'accuracy']].mean(axis=1)\n",
    "\n",
    "print(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            mean   std_err  min  max\n",
      "model                                               \n",
      "TeenyTinyLlama              2.37  0.056237  1.0  3.0\n",
      "TeenyTinyLlama-160m-CEP-ft  2.29  0.065590  1.0  4.0\n",
      "gpt-4o-mini-2024-07-18      2.41  0.075338  2.0  7.0\n"
     ]
    }
   ],
   "source": [
    "quality = df_final.groupby('model')['quality'].agg(['mean', 'sem', 'min', 'max'])\n",
    "\n",
    "# Renomear as colunas para melhor clareza\n",
    "summary_quality = quality.rename(columns={\n",
    "    'mean': 'mean',\n",
    "    'sem': 'std_err',\n",
    "    'min': 'min',\n",
    "    'max': 'max'\n",
    "})\n",
    "\n",
    "# Imprimir o DataFrame de resumo\n",
    "print(summary_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            mean   std_err  min  max\n",
      "model                                               \n",
      "TeenyTinyLlama              1.75  0.065713  1.0  4.0\n",
      "TeenyTinyLlama-160m-CEP-ft  1.83  0.092174  1.0  5.0\n",
      "gpt-4o-mini-2024-07-18      2.01  0.067412  1.0  6.0\n"
     ]
    }
   ],
   "source": [
    "agreement = df_final.groupby('model')['agreement'].agg(['mean', 'sem', 'min', 'max'])\n",
    "\n",
    "# Renomear as colunas para melhor clareza\n",
    "summary_agreement = agreement.rename(columns={\n",
    "    'mean': 'mean',\n",
    "    'sem': 'std_err',\n",
    "    'min': 'min',\n",
    "    'max': 'max'\n",
    "})\n",
    "\n",
    "# Imprimir o DataFrame de resumo\n",
    "print(summary_agreement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            mean   std_err  min  max\n",
      "model                                               \n",
      "TeenyTinyLlama              1.33  0.066750  0.0  4.0\n",
      "TeenyTinyLlama-160m-CEP-ft  1.38  0.077564  1.0  5.0\n",
      "gpt-4o-mini-2024-07-18      1.17  0.068246  1.0  7.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = df_final.groupby('model')['accuracy'].agg(['mean', 'sem', 'min', 'max'])\n",
    "\n",
    "# Renomear as colunas para melhor clareza\n",
    "summary_accuracy = accuracy.rename(columns={\n",
    "    'mean': 'mean',\n",
    "    'sem': 'std_err',\n",
    "    'min': 'min',\n",
    "    'max': 'max'\n",
    "})\n",
    "\n",
    "# Imprimir o DataFrame de resumo\n",
    "print(summary_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                mean   std_err       min       max\n",
      "model                                                             \n",
      "TeenyTinyLlama              1.816667  0.049549  1.000000  3.000000\n",
      "TeenyTinyLlama-160m-CEP-ft  1.833333  0.068247  1.000000  4.000000\n",
      "gpt-4o-mini-2024-07-18      1.863333  0.063404  1.333333  6.666667\n"
     ]
    }
   ],
   "source": [
    "mean_evaluation = df_final.groupby('model')['evaluation'].agg(['mean', 'sem', 'min', 'max'])\n",
    "\n",
    "# Renomear as colunas para melhor clareza\n",
    "summary_mean_evaluation = mean_evaluation.rename(columns={\n",
    "    'mean': 'mean',\n",
    "    'sem': 'std_err',\n",
    "    'min': 'min',\n",
    "    'max': 'max'\n",
    "})\n",
    "\n",
    "# Imprimir o DataFrame de resumo\n",
    "print(summary_mean_evaluation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
